## Implementation 
### a. Describe how you implemented the FlashAttention forward pass using CUDA. Mention the algorithm's key steps, such as matrix blocking, SRAM usage, and how intermediate results like scaling factors (ℓ and 𝑚) were calculated.

- Forward Pass 的邏輯都按照spec裡的Algorithm & seq-flashatten.c內容差不多:
  
1. Query-Key 內積 : 每個 Thread 計算 Q ⋅ K ^T的部分和，從 Shared Memory 中載入相應的 Tile 資料，進行累積計算，並將結果存放於score_tile。
2. Score_tile 乘以 Scaling Factor。
3. 更新row max。
4. 重新正規化：若 K 的下一個 Tile 被處理，則需要重新正規化先前累積的結果，根據新的最大值 m 和調整累積結果。
5. 與 Value 矩陣的相乘：將 Softmax 正規化後的結果與 V 的 Tile 相乘。更新 l 。
6. 寫回global memory。
   

- SRAM (Shared Memory) 的使用:
  
```
    // Shared memory 分配
    __shared__ float query_tile[BLOCK_ROWS][TILE_SIZE_K];
    __shared__ float key_tile[BLOCK_COLS][TILE_SIZE_K];
    __shared__ float value_tile[BLOCK_COLS][TILE_SIZE_K];
    __shared__ float score_tile[BLOCK_ROWS][BLOCK_COLS+1]; // +1避免bank conflict
```

- Matrix Blocking 的使用:  

將矩陣拆分成較小的Tile，每個 CUDA Block 負責處理 BLOCK_ROWS x BLOCK_COLS (32 * 32) 的大小的矩陣區塊，並在拆分為 Tiles，每個 Thread 負責更小的區域，處理elements數量固定為 TILE_ROWS x TILE_COLS (4 * 4) 。達到高效利用 CUDA 的並行計算能力。

- 中間結果 ℓ 和 𝑚 :
  
m：每row的最大值，用於確保 Softmax 計算的數值穩定性。  

ℓ：每row的指數和，用於最後的正規化。

### b. Explain how matrices Q, K, and V are divided into blocks and processed in parallel.    

把矩陣切成小 Block，讓每個小 Block 分配給不同的 GPU 並行處理，假設 Q、K 的大小是 sequence_length * dimension，按照固定的 BLOCK_ROWS 範圍去切割 sequence_length，同樣也按照固定的 BLOCK_COLS 範圍去切割 dimension，由於 𝑑 ∈ {32, 64}、𝑁 ∈ {128,....}
都為32的倍數，若有切割後不全的情況都給予補0。這樣一來，每個小區塊就是矩形的，這個矩形會被分配到 GPU 的一個 Block 中處理。

### c. Describe how you chose the block sizes B_r​ and B_c​ and why.

通常都是照環境的上限去設置，而blocksize支援最多的threads就是1024，所以會選擇32*32，因此把BLOCK_ROWS(B_r) 、 BLOCK_COLS(B_c)直接固定為32，方便撰寫。

### d. Specify the configurations for CUDA kernel launches, such as the number of threads per block, shared memory allocation, and grid dimensions.  

Grid 的的維度與作業的seq_length、batch_size有關、動態調整。
```
   dim3 blockDim(BLOCK_ROWS / TILE_COLS, BLOCK_COLS / TILE_ROWS);
   dim3 gridDim(batch_size, (sequence_length + BLOCK_ROWS - 1) / BLOCK_ROWS);
```

每個 Block 分配約 20 KB 的 Shared Memory，用於暫存Q、K、V 的 Tile 以及中間運算結果。


## Profiling Results
Provide the profiling results of following metrics on the kernel of your program using NVIDIA profiling tools. NVIDIA Profiler Guide.
- occupancy
- sm efficiency
- shared memory load/store throughput
- global load/store throughput

## Experiment & Analysis
### a. System Spec  

apollo gpu  

### b. Optimization  

Any optimizations after you port the algorithm on GPU, describe them with sentences and charts. Here are some techniques you can implement:
- Coalesced memory access
- Shared memory
- Handle bank conflict
- CUDA 2D alignment
- Occupancy optimization
- Streaming
- Others
- Additional charts with explanation and studies. The more, the better.  

## Experience & conclusion
What have you learned from this homework?
Feedback (optional)

